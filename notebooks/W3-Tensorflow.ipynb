{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack # \"horizontal stack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweets</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>label</th>\n",
       "      <th>tweets_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carlos_eggbot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:07 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'You heard me! Shoot me.', 'Junpei, you...', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecolo_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:11 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"i'm not straight but 20 bucks is 20 bu\", '\"ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllStarSMBot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:28 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"You'll never know if you don't go\\nYou'll nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saionji_en</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:52 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"why the fuck am i banana girl? i'll never die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KimClune</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:37:20 +0000 201...</td>\n",
       "      <td>329</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Chewing rather than drinking breakfast is AWE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatsDogsBOT</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:38:10 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>'[Discussion] If I say no, that should be it. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bluejovanka</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:38:14 +0000 201...</td>\n",
       "      <td>47</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"I'm staying in tonight watching someone with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anittavota4</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:39:19 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT BrettHillOwens2: #PremiosMTVMIAW #MTVBRMUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>justtraveluk</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:39:21 +0000 201...</td>\n",
       "      <td>11</td>\n",
       "      <td>bot</td>\n",
       "      <td>'The Top 5 Airports in the World for Departure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rhaudiencebot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:40:08 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'GET BUTCH, BITCH!', 'HEY RIFF, WHAT DO YOU DO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LexyintheCity</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:40:11 +0000 201...</td>\n",
       "      <td>69</td>\n",
       "      <td>bot</td>\n",
       "      <td>'A happy belated to this crazy fucking gemini ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kimberlymaich</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:07 +0000 201...</td>\n",
       "      <td>11</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Donna Miller Fry Thank you for following me!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>timotheeribeiro</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:23 +0000 201...</td>\n",
       "      <td>65</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Pinned to mes voyages on @Pinterest: La renco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>666dikuto</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:42 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"I'll fight for us till death do us part\", \"I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GLaDOSystem</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:55 +0000 201...</td>\n",
       "      <td>21</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"But I overcame my handicap. That's a true sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gotpie_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:42:31 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Get in the pie joffrey', 'look the pie', 'L̲͚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pawtersimms1</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:44:14 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Tottenham vs Liverpool FREE live stream: Watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mikan02862611</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:11 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"Another hour! It's June 02, 2019 at 03:45AM\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WeatherTucson</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:12 +0000 201...</td>\n",
       "      <td>7</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Right now: Sunny and 92F. Today: Sunny. High ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>asta_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:32 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>'When will there be a sequel to No.6 I need to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>taguigtwinktop</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:34 +0000 201...</td>\n",
       "      <td>10</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Hey Mackiedave@1988(@Mackiedave19881), thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stevenboss</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:44 +0000 201...</td>\n",
       "      <td>16</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Today 2:00 and 7:00 pm. Support The Lord’s Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>latikia</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:46:14 +0000 201...</td>\n",
       "      <td>288</td>\n",
       "      <td>bot</td>\n",
       "      <td>'ICYMI: The Spelling Bee Champs Interview That...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>positivenagi</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:00 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"Take a break, you've done so much today I'm p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cheesucheesu</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:11 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'down for the clown!', 'nya ha ha!', 'my aesth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fetisbieber</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:43 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT Moomoocorner: BDBML #PremiosMTVMIAW #MTVLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>anittavota5</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:08 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT dj_rakete: #PremiosMTVMIAW #MTVBRMUSICALAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EngkoBoti</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:16 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>'get together : 함께 모이다.\\nAll the family get to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ZikaSdv</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:32 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT monica1169: BDBML #PremiosMTVMIAW #MTVBRMU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lancxelot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:27 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>'\"I\\'m very proud to be wearing this shirt eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RevolutApp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:32:51 +0000 201...</td>\n",
       "      <td>881</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@ghostraccoon87 We're sorry to hear that! 🙁 L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Bakari_Sellers</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:31:55 +0000 201...</td>\n",
       "      <td>1695</td>\n",
       "      <td>human</td>\n",
       "      <td>'@AsteadWesley It’s all good. I Just know ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:33:53 +0000 201...</td>\n",
       "      <td>943</td>\n",
       "      <td>human</td>\n",
       "      <td>'@parasjain777 In that case, please share your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:00 +0000 201...</td>\n",
       "      <td>289</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@juliabullia_ I am sorry you feel this way. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>fly2midway</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:23 +0000 201...</td>\n",
       "      <td>394</td>\n",
       "      <td>human</td>\n",
       "      <td>'Yesterday, Commissioner Jamie L. Rhee met wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>WaltThurm3</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:44 +0000 201...</td>\n",
       "      <td>573</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@AtlantaFalcons @KBDeuce4 @MattBosher5 @KBDeu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>scottjohnson</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:59 +0000 201...</td>\n",
       "      <td>2489</td>\n",
       "      <td>human</td>\n",
       "      <td>'Just a reminder that WE pay for tariffs. Have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TOIBengaluru</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:35:02 +0000 201...</td>\n",
       "      <td>400</td>\n",
       "      <td>human</td>\n",
       "      <td>'Animal assisted therapy finds more takers in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>LASchoolPolice</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:35:32 +0000 201...</td>\n",
       "      <td>173</td>\n",
       "      <td>human</td>\n",
       "      <td>'Shelter in place will be lifted at 12:10 PM d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bbmayabb</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:36:41 +0000 201...</td>\n",
       "      <td>34</td>\n",
       "      <td>human</td>\n",
       "      <td>'@caisersoze84 @SaadoonMustafa So elegant .. y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>livexlive</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:02 +0000 201...</td>\n",
       "      <td>67</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@halseyph Hey! Just letting you know that we’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Its_Katka</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:36:54 +0000 201...</td>\n",
       "      <td>281</td>\n",
       "      <td>human</td>\n",
       "      <td>'Like one guy said I was “on the way to the vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>OregonGovBrown</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:36 +0000 201...</td>\n",
       "      <td>913</td>\n",
       "      <td>human</td>\n",
       "      <td>\"Climate change threatens our communities, our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ExpressNews</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:40 +0000 201...</td>\n",
       "      <td>283</td>\n",
       "      <td>human</td>\n",
       "      <td>'Texas Legislature declines to expand Medicaid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ChuckWendig</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:49 +0000 201...</td>\n",
       "      <td>4138</td>\n",
       "      <td>human</td>\n",
       "      <td>'@veschwab Tell them the VE stands for VENGEAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>chrisdeville</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:50 +0000 201...</td>\n",
       "      <td>240</td>\n",
       "      <td>human</td>\n",
       "      <td>'A ban on all fiancée / Beyoncé rhymes', 'RT @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:14 +0000 201...</td>\n",
       "      <td>1566</td>\n",
       "      <td>human</td>\n",
       "      <td>'@aclaireporter @thetrainline Ah apologies abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>UNDPAzerbaijan</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:20 +0000 201...</td>\n",
       "      <td>80</td>\n",
       "      <td>human</td>\n",
       "      <td>'NOW HIRING: an experienced &amp;amp; motivated #E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>DrNerdLove</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:39 +0000 201...</td>\n",
       "      <td>228</td>\n",
       "      <td>human</td>\n",
       "      <td>'“Excuse me, do you have the time to talk abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>CharlesSoule</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:40 +0000 201...</td>\n",
       "      <td>617</td>\n",
       "      <td>human</td>\n",
       "      <td>'@tmalghem I’m sure there will be signed copie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>fordm</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:43 +0000 201...</td>\n",
       "      <td>1202</td>\n",
       "      <td>human</td>\n",
       "      <td>\"15 members of Britain's House of Lords have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ChadPawson</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:48 +0000 201...</td>\n",
       "      <td>84</td>\n",
       "      <td>human</td>\n",
       "      <td>\"Curious if there is anyone in B.C. who has no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ericvdunn</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:18 +0000 201...</td>\n",
       "      <td>646</td>\n",
       "      <td>human</td>\n",
       "      <td>'Hurricane season at midnight. Lord let these ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RossDellenger</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:25 +0000 201...</td>\n",
       "      <td>645</td>\n",
       "      <td>human</td>\n",
       "      <td>'In Mississippi, gaining \"resort status\" is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>MrGerryCampbell</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:36 +0000 201...</td>\n",
       "      <td>81</td>\n",
       "      <td>human</td>\n",
       "      <td>'Serving Police Officer arrested for a #Domest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>davidmweissman</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:59 +0000 201...</td>\n",
       "      <td>444</td>\n",
       "      <td>human</td>\n",
       "      <td>'@MiheerDodhia @sunny @ewarren @FoxNews I wrot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PaulRieckhoff</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:02 +0000 201...</td>\n",
       "      <td>1386</td>\n",
       "      <td>human</td>\n",
       "      <td>'Blah. Nobody wants this except Ortiz who gets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Monster</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:40 +0000 201...</td>\n",
       "      <td>3638</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@ENIMSAJN_ A second job? If you're looking, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sligogaa</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:45 +0000 201...</td>\n",
       "      <td>174</td>\n",
       "      <td>human</td>\n",
       "      <td>'U17 Connacht League Rd2\\n\\n10mins 1st half\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FunSizeSuze</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:46 +0000 201...</td>\n",
       "      <td>312</td>\n",
       "      <td>human</td>\n",
       "      <td>'@soozaphone @cosmicshambles Ooh, yes! *pulls ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        screen_name                                             tweets  \\\n",
       "0     carlos_eggbot  [{'created_at': 'Sat Jun 01 18:36:07 +0000 201...   \n",
       "1      ecolo_ebooks  [{'created_at': 'Sat Jun 01 18:36:11 +0000 201...   \n",
       "2      AllStarSMBot  [{'created_at': 'Sat Jun 01 18:36:28 +0000 201...   \n",
       "3        saionji_en  [{'created_at': 'Sat Jun 01 18:36:52 +0000 201...   \n",
       "4          KimClune  [{'created_at': 'Sat Jun 01 18:37:20 +0000 201...   \n",
       "5       CatsDogsBOT  [{'created_at': 'Sat Jun 01 18:38:10 +0000 201...   \n",
       "6       bluejovanka  [{'created_at': 'Sat Jun 01 18:38:14 +0000 201...   \n",
       "7       anittavota4  [{'created_at': 'Sat Jun 01 18:39:19 +0000 201...   \n",
       "8      justtraveluk  [{'created_at': 'Sat Jun 01 18:39:21 +0000 201...   \n",
       "9     rhaudiencebot  [{'created_at': 'Sat Jun 01 18:40:08 +0000 201...   \n",
       "10    LexyintheCity  [{'created_at': 'Sat Jun 01 18:40:11 +0000 201...   \n",
       "11    kimberlymaich  [{'created_at': 'Sat Jun 01 18:41:07 +0000 201...   \n",
       "12  timotheeribeiro  [{'created_at': 'Sat Jun 01 18:41:23 +0000 201...   \n",
       "13        666dikuto  [{'created_at': 'Sat Jun 01 18:41:42 +0000 201...   \n",
       "14      GLaDOSystem  [{'created_at': 'Sat Jun 01 18:41:55 +0000 201...   \n",
       "15    gotpie_ebooks  [{'created_at': 'Sat Jun 01 18:42:31 +0000 201...   \n",
       "16     Pawtersimms1  [{'created_at': 'Sat Jun 01 18:44:14 +0000 201...   \n",
       "17    mikan02862611  [{'created_at': 'Sat Jun 01 18:45:11 +0000 201...   \n",
       "18    WeatherTucson  [{'created_at': 'Sat Jun 01 18:45:12 +0000 201...   \n",
       "19      asta_ebooks  [{'created_at': 'Sat Jun 01 18:45:32 +0000 201...   \n",
       "20   taguigtwinktop  [{'created_at': 'Sat Jun 01 18:45:34 +0000 201...   \n",
       "21       stevenboss  [{'created_at': 'Sat Jun 01 18:45:44 +0000 201...   \n",
       "22          latikia  [{'created_at': 'Sat Jun 01 18:46:14 +0000 201...   \n",
       "23     positivenagi  [{'created_at': 'Sat Jun 01 18:50:00 +0000 201...   \n",
       "24     cheesucheesu  [{'created_at': 'Sat Jun 01 18:50:11 +0000 201...   \n",
       "25      fetisbieber  [{'created_at': 'Sat Jun 01 18:50:43 +0000 201...   \n",
       "26      anittavota5  [{'created_at': 'Sat Jun 01 18:51:08 +0000 201...   \n",
       "27        EngkoBoti  [{'created_at': 'Sat Jun 01 18:51:16 +0000 201...   \n",
       "28          ZikaSdv  [{'created_at': 'Sat Jun 01 18:51:32 +0000 201...   \n",
       "29        lancxelot  [{'created_at': 'Sat Jun 01 18:51:27 +0000 201...   \n",
       "..              ...                                                ...   \n",
       "70       RevolutApp  [{'created_at': 'Fri May 31 18:32:51 +0000 201...   \n",
       "71   Bakari_Sellers  [{'created_at': 'Fri May 31 18:31:55 +0000 201...   \n",
       "72       AmazonHelp  [{'created_at': 'Fri May 31 18:33:53 +0000 201...   \n",
       "73          UPSHelp  [{'created_at': 'Fri May 31 18:34:00 +0000 201...   \n",
       "74       fly2midway  [{'created_at': 'Fri May 31 18:34:23 +0000 201...   \n",
       "75       WaltThurm3  [{'created_at': 'Fri May 31 18:34:44 +0000 201...   \n",
       "76     scottjohnson  [{'created_at': 'Fri May 31 18:34:59 +0000 201...   \n",
       "77     TOIBengaluru  [{'created_at': 'Fri May 31 18:35:02 +0000 201...   \n",
       "78   LASchoolPolice  [{'created_at': 'Fri May 31 18:35:32 +0000 201...   \n",
       "79         bbmayabb  [{'created_at': 'Fri May 31 18:36:41 +0000 201...   \n",
       "80        livexlive  [{'created_at': 'Fri May 31 18:37:02 +0000 201...   \n",
       "81        Its_Katka  [{'created_at': 'Fri May 31 18:36:54 +0000 201...   \n",
       "82   OregonGovBrown  [{'created_at': 'Fri May 31 18:37:36 +0000 201...   \n",
       "83      ExpressNews  [{'created_at': 'Fri May 31 18:37:40 +0000 201...   \n",
       "84      ChuckWendig  [{'created_at': 'Fri May 31 18:37:49 +0000 201...   \n",
       "85     chrisdeville  [{'created_at': 'Fri May 31 18:37:50 +0000 201...   \n",
       "86     VirginTrains  [{'created_at': 'Fri May 31 18:38:14 +0000 201...   \n",
       "87   UNDPAzerbaijan  [{'created_at': 'Fri May 31 18:38:20 +0000 201...   \n",
       "88       DrNerdLove  [{'created_at': 'Fri May 31 18:38:39 +0000 201...   \n",
       "89     CharlesSoule  [{'created_at': 'Fri May 31 18:38:40 +0000 201...   \n",
       "90            fordm  [{'created_at': 'Fri May 31 18:38:43 +0000 201...   \n",
       "91       ChadPawson  [{'created_at': 'Fri May 31 18:38:48 +0000 201...   \n",
       "92        ericvdunn  [{'created_at': 'Fri May 31 18:39:18 +0000 201...   \n",
       "93    RossDellenger  [{'created_at': 'Fri May 31 18:39:25 +0000 201...   \n",
       "94  MrGerryCampbell  [{'created_at': 'Fri May 31 18:39:36 +0000 201...   \n",
       "95   davidmweissman  [{'created_at': 'Fri May 31 18:39:59 +0000 201...   \n",
       "96    PaulRieckhoff  [{'created_at': 'Fri May 31 18:40:02 +0000 201...   \n",
       "97          Monster  [{'created_at': 'Fri May 31 18:40:40 +0000 201...   \n",
       "98         sligogaa  [{'created_at': 'Fri May 31 18:40:45 +0000 201...   \n",
       "99      FunSizeSuze  [{'created_at': 'Fri May 31 18:40:46 +0000 201...   \n",
       "\n",
       "    listed_count  label                                       tweets_texts  \n",
       "0              0    bot  'You heard me! Shoot me.', 'Junpei, you...', '...  \n",
       "1              2    bot  \"i'm not straight but 20 bucks is 20 bu\", '\"ec...  \n",
       "2              3    bot  \"You'll never know if you don't go\\nYou'll nev...  \n",
       "3              3    bot  \"why the fuck am i banana girl? i'll never die...  \n",
       "4            329    bot  'Chewing rather than drinking breakfast is AWE...  \n",
       "5              3    bot  '[Discussion] If I say no, that should be it. ...  \n",
       "6             47    bot  \"I'm staying in tonight watching someone with ...  \n",
       "7              0    bot  'RT BrettHillOwens2: #PremiosMTVMIAW #MTVBRMUS...  \n",
       "8             11    bot  'The Top 5 Airports in the World for Departure...  \n",
       "9              0    bot  'GET BUTCH, BITCH!', 'HEY RIFF, WHAT DO YOU DO...  \n",
       "10            69    bot  'A happy belated to this crazy fucking gemini ...  \n",
       "11            11    bot  'Donna Miller Fry Thank you for following me!!...  \n",
       "12            65    bot  'Pinned to mes voyages on @Pinterest: La renco...  \n",
       "13             0    bot  \"I'll fight for us till death do us part\", \"I ...  \n",
       "14            21    bot  \"But I overcame my handicap. That's a true sto...  \n",
       "15             0    bot  'Get in the pie joffrey', 'look the pie', 'L̲͚...  \n",
       "16             0    bot  'Tottenham vs Liverpool FREE live stream: Watc...  \n",
       "17             0    bot  \"Another hour! It's June 02, 2019 at 03:45AM\",...  \n",
       "18             7    bot  'Right now: Sunny and 92F. Today: Sunny. High ...  \n",
       "19             2    bot  'When will there be a sequel to No.6 I need to...  \n",
       "20            10    bot  'Hey Mackiedave@1988(@Mackiedave19881), thank ...  \n",
       "21            16    bot  'Today 2:00 and 7:00 pm. Support The Lord’s Cu...  \n",
       "22           288    bot  'ICYMI: The Spelling Bee Champs Interview That...  \n",
       "23             2    bot  \"Take a break, you've done so much today I'm p...  \n",
       "24             0    bot  'down for the clown!', 'nya ha ha!', 'my aesth...  \n",
       "25             0    bot  'RT Moomoocorner: BDBML #PremiosMTVMIAW #MTVLA...  \n",
       "26             0    bot  'RT dj_rakete: #PremiosMTVMIAW #MTVBRMUSICALAN...  \n",
       "27             2    bot  'get together : 함께 모이다.\\nAll the family get to...  \n",
       "28             0    bot  'RT monica1169: BDBML #PremiosMTVMIAW #MTVBRMU...  \n",
       "29             2    bot  '\"I\\'m very proud to be wearing this shirt eve...  \n",
       "..           ...    ...                                                ...  \n",
       "70           881  human  \"@ghostraccoon87 We're sorry to hear that! 🙁 L...  \n",
       "71          1695  human  '@AsteadWesley It’s all good. I Just know ther...  \n",
       "72           943  human  '@parasjain777 In that case, please share your...  \n",
       "73           289  human  \"@juliabullia_ I am sorry you feel this way. W...  \n",
       "74           394  human  'Yesterday, Commissioner Jamie L. Rhee met wit...  \n",
       "75           573  human  \"@AtlantaFalcons @KBDeuce4 @MattBosher5 @KBDeu...  \n",
       "76          2489  human  'Just a reminder that WE pay for tariffs. Have...  \n",
       "77           400  human  'Animal assisted therapy finds more takers in ...  \n",
       "78           173  human  'Shelter in place will be lifted at 12:10 PM d...  \n",
       "79            34  human  '@caisersoze84 @SaadoonMustafa So elegant .. y...  \n",
       "80            67  human  \"@halseyph Hey! Just letting you know that we’...  \n",
       "81           281  human  'Like one guy said I was “on the way to the vi...  \n",
       "82           913  human  \"Climate change threatens our communities, our...  \n",
       "83           283  human  'Texas Legislature declines to expand Medicaid...  \n",
       "84          4138  human  '@veschwab Tell them the VE stands for VENGEAN...  \n",
       "85           240  human  'A ban on all fiancée / Beyoncé rhymes', 'RT @...  \n",
       "86          1566  human  '@aclaireporter @thetrainline Ah apologies abo...  \n",
       "87            80  human  'NOW HIRING: an experienced &amp; motivated #E...  \n",
       "88           228  human  '“Excuse me, do you have the time to talk abou...  \n",
       "89           617  human  '@tmalghem I’m sure there will be signed copie...  \n",
       "90          1202  human  \"15 members of Britain's House of Lords have b...  \n",
       "91            84  human  \"Curious if there is anyone in B.C. who has no...  \n",
       "92           646  human  'Hurricane season at midnight. Lord let these ...  \n",
       "93           645  human  'In Mississippi, gaining \"resort status\" is a ...  \n",
       "94            81  human  'Serving Police Officer arrested for a #Domest...  \n",
       "95           444  human  '@MiheerDodhia @sunny @ewarren @FoxNews I wrot...  \n",
       "96          1386  human  'Blah. Nobody wants this except Ortiz who gets...  \n",
       "97          3638  human  \"@ENIMSAJN_ A second job? If you're looking, w...  \n",
       "98           174  human  'U17 Connacht League Rd2\\n\\n10mins 1st half\\nS...  \n",
       "99           312  human  '@soozaphone @cosmicshambles Ooh, yes! *pulls ...  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(directory):\n",
    "    bots = []\n",
    "    humans = []\n",
    "    folder = ['/bots', '/humans']\n",
    "    name = '/*.json.gz'\n",
    "    for f in folder:\n",
    "        paths = glob.glob(directory + f + name)\n",
    "        for p in paths:\n",
    "            with gzip.open(p, 'r') as file:\n",
    "                for line in file:\n",
    "                    if f == folder[0]:\n",
    "                        js = json.loads(line)\n",
    "                        if 'tweets' in js:\n",
    "                            bots.append(js)\n",
    "                    elif f == folder[1]:\n",
    "                        js = json.loads(line)\n",
    "                        if 'tweets' in js:\n",
    "                            humans.append(js)\n",
    "    df_bots = pd.DataFrame(bots)[['screen_name', 'tweets', 'listed_count']]\n",
    "    df_bots['label'] = 'bot'\n",
    "    df_humans = pd.DataFrame(humans)[['screen_name', 'tweets', 'listed_count']]\n",
    "    df_humans['label'] = 'human'\n",
    "    frames = [df_bots, df_humans]\n",
    "    df = pd.concat(frames)\n",
    "    users = bots + humans\n",
    "    # tweets_avg_mentions = []\n",
    "    # tweets_avg_urls = []\n",
    "    # factor = 100\n",
    "    tweets_texts = []\n",
    "    for u in users:\n",
    "        tweets = u['tweets']  # a list of dicts\n",
    "        texts = [t['full_text'] for t in tweets]\n",
    "        tweets_texts.append(str(texts).strip('[]'))\n",
    "    df['tweets_texts'] = tweets_texts\n",
    "    return df\n",
    "df = load_data('/Users/lcj/small')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name     object\n",
       "tweets          object\n",
       "listed_count     int64\n",
       "label           object\n",
       "tweets_texts    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_features(texts):\n",
    "    count_mention = 0\n",
    "    count_url = 0\n",
    "    factor = 100\n",
    "    features = {}\n",
    "    for s in texts:\n",
    "        if 'http' in s:\n",
    "            count_url += 1\n",
    "        if '@' in s:\n",
    "            count_mention += 1\n",
    "    if len(texts) == 0:\n",
    "        features['tweets_avg_urls'] = 0\n",
    "        features['tweets_avg_mentions'] = 0\n",
    "    else:\n",
    "        features['tweets_avg_urls'] = factor * count_url / len(texts)\n",
    "        features['tweets_avg_mentions'] = factor * count_mention / len(texts)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    ## Add your code to create features.\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    for i, row in df.iterrows():\n",
    "        tweets = row['tweets']\n",
    "        texts = [t['full_text'] for t in tweets]\n",
    "        features = get_tweets_features(texts)\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweets_avg_urls': 1, 'tweets_avg_mentions': 0}\n"
     ]
    }
   ],
   "source": [
    "X, dict_vec = make_features(df)\n",
    "print(dict_vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(min_df=0.03, max_df=0.8, ngram_range=(3, 3))\n",
    "X_words = count_vec.fit_transform(df.tweets_texts)\n",
    "# get_f(count_vec, X_words)\n",
    "optimal_X_all = hstack([X, X_words]).tocsr()\n",
    "# print(type(X_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtvbrclipebanana mtvbrhinobolarebola mtvbrfeatondadiferente\t1400\n",
      "mtvbrmusicalanitta mtvbrclipebanana mtvbrhinobolarebola\t1400\n",
      "mtvlastoriesanitta mtvlaviralanitta mtvlashiprip\t1200\n",
      "          01 2019 at\t661\n",
      "        june 01 2019\t661\n",
      "       thank you for\t482\n",
      "       here https co\t277\n",
      "       more https co\t275\n",
      "         at https co\t270\n",
      "         to https co\t256\n"
     ]
    }
   ],
   "source": [
    "# top terms?\n",
    "def print_top_words(X_words, count_vec, n=10):\n",
    "    features = count_vec.get_feature_names()\n",
    "    word_counts = X_words.sum(axis=0).A1\n",
    "    for i in np.argsort(word_counts)[::-1][:n]:\n",
    "        print('%20s\\t%d' % (features[i], word_counts[i]))\n",
    "\n",
    "print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1041)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)\n",
    "optimal_X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweets_avg_urls\t                 bot\t3657\n",
      "     tweets_avg_urls\t               human\t5491\n",
      " tweets_avg_mentions\t                 bot\t905\n",
      " tweets_avg_mentions\t               human\t6123\n"
     ]
    }
   ],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)\n",
    "# how often does each word appear in each class?\n",
    "for word, idx in dict_vec.vocabulary_.items():\n",
    "    for class_name in class_names:\n",
    "        class_idx = np.where(y==class_name)[0]\n",
    "        print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                16672     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 16,961\n",
      "Trainable params: 16,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Dropout, Flatten\n",
    "vocab_size = 10000\n",
    "dropout_rate = .2\n",
    "model = keras.Sequential()\n",
    "# model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "# model.add(Dropout(rate=dropout_rate))\n",
    "# model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16,input_shape=(1041,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(Dropout(rate=dropout_rate))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "#model.build((200,1041))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=adam,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_X_all, y =shuffle(optimal_X_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1 if i == 'human' else 0 for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy import *\n",
    "# csr_matrix((3, 4), dtype=np.int8).toarray()\n",
    "#arr = sparse.lil_matrix(optimal_X_all).toarray()\n",
    "\n",
    "x_val = optimal_X_all[:20]\n",
    "partial_x_train = optimal_X_all[20:]\n",
    "\n",
    "y_val = y[:20]\n",
    "partial_y_train = y[20:]\n",
    "\n",
    "print(type(partial_x_train))\n",
    "print(type(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.8821 - accuracy: 0.6300 - val_loss: 0.7938 - val_accuracy: 0.6100\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.6301 - accuracy: 0.6600 - val_loss: 0.8300 - val_accuracy: 0.5700\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.4623 - accuracy: 0.8000 - val_loss: 0.8473 - val_accuracy: 0.5500\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.5891 - accuracy: 0.7400 - val_loss: 0.8405 - val_accuracy: 0.5600\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.5905 - accuracy: 0.7500 - val_loss: 0.8185 - val_accuracy: 0.5800\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 50us/sample - loss: 0.4777 - accuracy: 0.8000 - val_loss: 0.7986 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 45us/sample - loss: 0.4861 - accuracy: 0.8400 - val_loss: 0.7796 - val_accuracy: 0.6100\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 36us/sample - loss: 0.3952 - accuracy: 0.8400 - val_loss: 0.7569 - val_accuracy: 0.6100\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.3071 - accuracy: 0.8600 - val_loss: 0.7299 - val_accuracy: 0.6400\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 44us/sample - loss: 0.3398 - accuracy: 0.8700 - val_loss: 0.7052 - val_accuracy: 0.6600\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.2975 - accuracy: 0.9100 - val_loss: 0.6814 - val_accuracy: 0.6800\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.3441 - accuracy: 0.8800 - val_loss: 0.6579 - val_accuracy: 0.6800\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 48us/sample - loss: 0.3161 - accuracy: 0.9200 - val_loss: 0.6391 - val_accuracy: 0.6900\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.2038 - accuracy: 0.9200 - val_loss: 0.6232 - val_accuracy: 0.6900\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.2549 - accuracy: 0.9300 - val_loss: 0.6097 - val_accuracy: 0.6900\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.2046 - accuracy: 0.9300 - val_loss: 0.5976 - val_accuracy: 0.7100\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.2325 - accuracy: 0.9100 - val_loss: 0.5876 - val_accuracy: 0.7300\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.2249 - accuracy: 0.9200 - val_loss: 0.5810 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.2073 - accuracy: 0.9200 - val_loss: 0.5773 - val_accuracy: 0.7600\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.2747 - accuracy: 0.9100 - val_loss: 0.5758 - val_accuracy: 0.7700\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.2338 - accuracy: 0.9000 - val_loss: 0.5757 - val_accuracy: 0.7600\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.1667 - accuracy: 0.9400 - val_loss: 0.5768 - val_accuracy: 0.7600\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 35us/sample - loss: 0.1797 - accuracy: 0.9200 - val_loss: 0.5789 - val_accuracy: 0.7400\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.1836 - accuracy: 0.9100 - val_loss: 0.5811 - val_accuracy: 0.7300\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 45us/sample - loss: 0.1733 - accuracy: 0.9200 - val_loss: 0.5843 - val_accuracy: 0.7300\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.1287 - accuracy: 0.9700 - val_loss: 0.5873 - val_accuracy: 0.7300\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.1764 - accuracy: 0.9300 - val_loss: 0.5919 - val_accuracy: 0.7400\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.2141 - accuracy: 0.9200 - val_loss: 0.5969 - val_accuracy: 0.7400\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.1494 - accuracy: 0.9400 - val_loss: 0.6019 - val_accuracy: 0.7300\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.1753 - accuracy: 0.9500 - val_loss: 0.6080 - val_accuracy: 0.7300\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 43us/sample - loss: 0.1829 - accuracy: 0.9200 - val_loss: 0.6129 - val_accuracy: 0.7300\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.1548 - accuracy: 0.9500 - val_loss: 0.6173 - val_accuracy: 0.7300\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.1283 - accuracy: 0.9500 - val_loss: 0.6218 - val_accuracy: 0.7300\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.1006 - accuracy: 0.9700 - val_loss: 0.6259 - val_accuracy: 0.7200\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.1207 - accuracy: 0.9600 - val_loss: 0.6308 - val_accuracy: 0.7100\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 47us/sample - loss: 0.1202 - accuracy: 0.9600 - val_loss: 0.6347 - val_accuracy: 0.7100\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.1260 - accuracy: 0.9500 - val_loss: 0.6391 - val_accuracy: 0.7100\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 46us/sample - loss: 0.1509 - accuracy: 0.9500 - val_loss: 0.6422 - val_accuracy: 0.7100\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 43us/sample - loss: 0.0791 - accuracy: 0.9800 - val_loss: 0.6460 - val_accuracy: 0.7100\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0934 - accuracy: 0.9700 - val_loss: 0.6492 - val_accuracy: 0.7100\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 47us/sample - loss: 0.1460 - accuracy: 0.9500 - val_loss: 0.6528 - val_accuracy: 0.7200\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.1163 - accuracy: 0.9800 - val_loss: 0.6552 - val_accuracy: 0.7200\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.0983 - accuracy: 0.9700 - val_loss: 0.6572 - val_accuracy: 0.7200\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 50us/sample - loss: 0.0813 - accuracy: 0.9800 - val_loss: 0.6592 - val_accuracy: 0.7200\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 43us/sample - loss: 0.0953 - accuracy: 0.9700 - val_loss: 0.6583 - val_accuracy: 0.7200\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.0747 - accuracy: 0.9800 - val_loss: 0.6592 - val_accuracy: 0.7200\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 56us/sample - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.6563 - val_accuracy: 0.7200\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.0968 - accuracy: 0.9700 - val_loss: 0.6529 - val_accuracy: 0.7200\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.0854 - accuracy: 0.9700 - val_loss: 0.6511 - val_accuracy: 0.7200\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 45us/sample - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.7200\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.7200\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0946 - accuracy: 0.9800 - val_loss: 0.6467 - val_accuracy: 0.7200\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 43us/sample - loss: 0.1061 - accuracy: 0.9700 - val_loss: 0.6460 - val_accuracy: 0.7200\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0731 - accuracy: 0.9900 - val_loss: 0.6483 - val_accuracy: 0.7200\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 50us/sample - loss: 0.0624 - accuracy: 0.9900 - val_loss: 0.6477 - val_accuracy: 0.7400\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 36us/sample - loss: 0.0675 - accuracy: 0.9900 - val_loss: 0.6497 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0785 - accuracy: 0.9800 - val_loss: 0.6525 - val_accuracy: 0.7400\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 45us/sample - loss: 0.0736 - accuracy: 0.9800 - val_loss: 0.6577 - val_accuracy: 0.7400\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.1174 - accuracy: 0.9600 - val_loss: 0.6619 - val_accuracy: 0.7400\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.6636 - val_accuracy: 0.7400\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 36us/sample - loss: 0.0716 - accuracy: 0.9800 - val_loss: 0.6633 - val_accuracy: 0.7400\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0684 - accuracy: 0.9900 - val_loss: 0.6636 - val_accuracy: 0.7400\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 34us/sample - loss: 0.0693 - accuracy: 0.9900 - val_loss: 0.6698 - val_accuracy: 0.7400\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0682 - accuracy: 0.9800 - val_loss: 0.6716 - val_accuracy: 0.7400\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 48us/sample - loss: 0.0539 - accuracy: 0.9900 - val_loss: 0.6737 - val_accuracy: 0.7400\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 45us/sample - loss: 0.0641 - accuracy: 0.9900 - val_loss: 0.6754 - val_accuracy: 0.7400\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 33us/sample - loss: 0.0914 - accuracy: 0.9600 - val_loss: 0.6763 - val_accuracy: 0.7400\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 45us/sample - loss: 0.0668 - accuracy: 0.9800 - val_loss: 0.6771 - val_accuracy: 0.7400\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.0490 - accuracy: 0.9900 - val_loss: 0.6781 - val_accuracy: 0.7400\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 36us/sample - loss: 0.0582 - accuracy: 0.9900 - val_loss: 0.6790 - val_accuracy: 0.7400\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.7400\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0534 - accuracy: 0.9900 - val_loss: 0.6814 - val_accuracy: 0.7400\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.0509 - accuracy: 0.9900 - val_loss: 0.6839 - val_accuracy: 0.7400\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.6859 - val_accuracy: 0.7300\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 42us/sample - loss: 0.0461 - accuracy: 0.9900 - val_loss: 0.6877 - val_accuracy: 0.7300\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 33us/sample - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.6900 - val_accuracy: 0.7300\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 40us/sample - loss: 0.0642 - accuracy: 0.9900 - val_loss: 0.6919 - val_accuracy: 0.7300\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.6942 - val_accuracy: 0.7300\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 34us/sample - loss: 0.0515 - accuracy: 0.9900 - val_loss: 0.6966 - val_accuracy: 0.7300\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 35us/sample - loss: 0.0676 - accuracy: 0.9800 - val_loss: 0.6974 - val_accuracy: 0.7400\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0441 - accuracy: 0.9900 - val_loss: 0.6986 - val_accuracy: 0.7400\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.7000 - val_accuracy: 0.7400\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.0447 - accuracy: 0.9900 - val_loss: 0.7025 - val_accuracy: 0.7400\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.0458 - accuracy: 0.9900 - val_loss: 0.7053 - val_accuracy: 0.7400\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.0575 - accuracy: 0.9900 - val_loss: 0.7087 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 34us/sample - loss: 0.0434 - accuracy: 0.9900 - val_loss: 0.7122 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 34us/sample - loss: 0.0441 - accuracy: 0.9900 - val_loss: 0.7155 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.0653 - accuracy: 0.9700 - val_loss: 0.7177 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 41us/sample - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.7198 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 35us/sample - loss: 0.0442 - accuracy: 0.9900 - val_loss: 0.7221 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0457 - accuracy: 0.9900 - val_loss: 0.7251 - val_accuracy: 0.7400\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 37us/sample - loss: 0.0525 - accuracy: 0.9800 - val_loss: 0.7276 - val_accuracy: 0.7400\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 34us/sample - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.7303 - val_accuracy: 0.7400\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.7400\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.7400\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 38us/sample - loss: 0.0408 - accuracy: 0.9900 - val_loss: 0.7396 - val_accuracy: 0.7400\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 32us/sample - loss: 0.0394 - accuracy: 0.9900 - val_loss: 0.7421 - val_accuracy: 0.7400\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 39us/sample - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.7400\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 43us/sample - loss: 0.0439 - accuracy: 0.9900 - val_loss: 0.7474 - val_accuracy: 0.7400\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 35us/sample - loss: 0.0372 - accuracy: 0.9900 - val_loss: 0.7501 - val_accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train.todense(),\n",
    "                    partial_y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val.todense(), y_val),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
