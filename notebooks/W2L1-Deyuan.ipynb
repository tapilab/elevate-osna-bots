{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will\n",
    "- read our project data into a Pandas DataFrame\n",
    "- write a function to compute simple features for each row of the data frame\n",
    "- fit a LogisticRegression model to the data\n",
    "- print the top coefficients\n",
    "- compute measures of accuracy\n",
    "\n",
    "I've given you starter code below. You should:\n",
    "- First, try to get it to work with your data. It may require changing the load_data file to match the requirements of your data (e.g., what is the object you are classifying -- a tweet, a user, a news article?)\n",
    "- Second, you should add additional features to the make_features function:\n",
    "  - Be creative. It could be additional word features, or other meta data about the user, date, etc.\n",
    "- As you try out different feature combinations, print out the coefficients and accuracy scores\n",
    "- List any features that seem to improve accuracy. Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweets</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>label</th>\n",
       "      <th>tweets_avg_urls</th>\n",
       "      <th>tweets_avg_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carlos_eggbot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:07 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecolo_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:11 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllStarSMBot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:28 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saionji_en</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:52 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KimClune</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:37:20 +0000 201...</td>\n",
       "      <td>329</td>\n",
       "      <td>bot</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatsDogsBOT</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:38:10 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bluejovanka</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:38:14 +0000 201...</td>\n",
       "      <td>47</td>\n",
       "      <td>bot</td>\n",
       "      <td>37.688442</td>\n",
       "      <td>32.160804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anittavota4</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:39:19 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>justtraveluk</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:39:21 +0000 201...</td>\n",
       "      <td>11</td>\n",
       "      <td>bot</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rhaudiencebot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:40:08 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LexyintheCity</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:40:11 +0000 201...</td>\n",
       "      <td>69</td>\n",
       "      <td>bot</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kimberlymaich</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:07 +0000 201...</td>\n",
       "      <td>11</td>\n",
       "      <td>bot</td>\n",
       "      <td>31.313131</td>\n",
       "      <td>82.323232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>timotheeribeiro</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:23 +0000 201...</td>\n",
       "      <td>65</td>\n",
       "      <td>bot</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>666dikuto</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:42 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GLaDOSystem</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:55 +0000 201...</td>\n",
       "      <td>21</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gotpie_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:42:31 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pawtersimms1</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:44:14 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mikan02862611</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:11 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WeatherTucson</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:12 +0000 201...</td>\n",
       "      <td>7</td>\n",
       "      <td>bot</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>asta_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:32 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>taguigtwinktop</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:34 +0000 201...</td>\n",
       "      <td>10</td>\n",
       "      <td>bot</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stevenboss</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:44 +0000 201...</td>\n",
       "      <td>16</td>\n",
       "      <td>bot</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>latikia</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:46:14 +0000 201...</td>\n",
       "      <td>288</td>\n",
       "      <td>bot</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>positivenagi</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:00 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cheesucheesu</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:11 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fetisbieber</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:43 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>anittavota5</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:08 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EngkoBoti</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:16 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ZikaSdv</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:32 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lancxelot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:27 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>69.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RevolutApp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:32:51 +0000 201...</td>\n",
       "      <td>881</td>\n",
       "      <td>human</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Bakari_Sellers</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:31:55 +0000 201...</td>\n",
       "      <td>1695</td>\n",
       "      <td>human</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:33:53 +0000 201...</td>\n",
       "      <td>943</td>\n",
       "      <td>human</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:00 +0000 201...</td>\n",
       "      <td>289</td>\n",
       "      <td>human</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>fly2midway</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:23 +0000 201...</td>\n",
       "      <td>394</td>\n",
       "      <td>human</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>WaltThurm3</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:44 +0000 201...</td>\n",
       "      <td>573</td>\n",
       "      <td>human</td>\n",
       "      <td>40.201005</td>\n",
       "      <td>70.351759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>scottjohnson</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:59 +0000 201...</td>\n",
       "      <td>2489</td>\n",
       "      <td>human</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>61.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TOIBengaluru</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:35:02 +0000 201...</td>\n",
       "      <td>400</td>\n",
       "      <td>human</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>LASchoolPolice</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:35:32 +0000 201...</td>\n",
       "      <td>173</td>\n",
       "      <td>human</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>79.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bbmayabb</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:36:41 +0000 201...</td>\n",
       "      <td>34</td>\n",
       "      <td>human</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>livexlive</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:02 +0000 201...</td>\n",
       "      <td>67</td>\n",
       "      <td>human</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Its_Katka</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:36:54 +0000 201...</td>\n",
       "      <td>281</td>\n",
       "      <td>human</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>OregonGovBrown</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:36 +0000 201...</td>\n",
       "      <td>913</td>\n",
       "      <td>human</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>44.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ExpressNews</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:40 +0000 201...</td>\n",
       "      <td>283</td>\n",
       "      <td>human</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ChuckWendig</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:49 +0000 201...</td>\n",
       "      <td>4138</td>\n",
       "      <td>human</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>79.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>chrisdeville</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:50 +0000 201...</td>\n",
       "      <td>240</td>\n",
       "      <td>human</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:14 +0000 201...</td>\n",
       "      <td>1566</td>\n",
       "      <td>human</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>UNDPAzerbaijan</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:20 +0000 201...</td>\n",
       "      <td>80</td>\n",
       "      <td>human</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>DrNerdLove</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:39 +0000 201...</td>\n",
       "      <td>228</td>\n",
       "      <td>human</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>CharlesSoule</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:40 +0000 201...</td>\n",
       "      <td>617</td>\n",
       "      <td>human</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>fordm</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:43 +0000 201...</td>\n",
       "      <td>1202</td>\n",
       "      <td>human</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ChadPawson</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:48 +0000 201...</td>\n",
       "      <td>84</td>\n",
       "      <td>human</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ericvdunn</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:18 +0000 201...</td>\n",
       "      <td>646</td>\n",
       "      <td>human</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RossDellenger</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:25 +0000 201...</td>\n",
       "      <td>645</td>\n",
       "      <td>human</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>40.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>MrGerryCampbell</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:36 +0000 201...</td>\n",
       "      <td>81</td>\n",
       "      <td>human</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>davidmweissman</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:59 +0000 201...</td>\n",
       "      <td>444</td>\n",
       "      <td>human</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PaulRieckhoff</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:02 +0000 201...</td>\n",
       "      <td>1386</td>\n",
       "      <td>human</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>84.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Monster</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:40 +0000 201...</td>\n",
       "      <td>3638</td>\n",
       "      <td>human</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sligogaa</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:45 +0000 201...</td>\n",
       "      <td>174</td>\n",
       "      <td>human</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FunSizeSuze</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:46 +0000 201...</td>\n",
       "      <td>312</td>\n",
       "      <td>human</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>84.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                             tweets  \\\n",
       "0    carlos_eggbot  [{'created_at': 'Sat Jun 01 18:36:07 +0000 201...   \n",
       "1     ecolo_ebooks  [{'created_at': 'Sat Jun 01 18:36:11 +0000 201...   \n",
       "2     AllStarSMBot  [{'created_at': 'Sat Jun 01 18:36:28 +0000 201...   \n",
       "3       saionji_en  [{'created_at': 'Sat Jun 01 18:36:52 +0000 201...   \n",
       "4         KimClune  [{'created_at': 'Sat Jun 01 18:37:20 +0000 201...   \n",
       "..             ...                                                ...   \n",
       "95  davidmweissman  [{'created_at': 'Fri May 31 18:39:59 +0000 201...   \n",
       "96   PaulRieckhoff  [{'created_at': 'Fri May 31 18:40:02 +0000 201...   \n",
       "97         Monster  [{'created_at': 'Fri May 31 18:40:40 +0000 201...   \n",
       "98        sligogaa  [{'created_at': 'Fri May 31 18:40:45 +0000 201...   \n",
       "99     FunSizeSuze  [{'created_at': 'Fri May 31 18:40:46 +0000 201...   \n",
       "\n",
       "    listed_count  label  tweets_avg_urls  tweets_avg_mentions  \n",
       "0              0    bot             10.5                  0.0  \n",
       "1              2    bot              0.0                  0.0  \n",
       "2              3    bot              0.0                  0.0  \n",
       "3              3    bot              0.0                  0.0  \n",
       "4            329    bot             28.5                  2.5  \n",
       "..           ...    ...              ...                  ...  \n",
       "95           444  human             27.5                 82.0  \n",
       "96          1386  human             45.5                 84.5  \n",
       "97          3638  human             99.0                100.0  \n",
       "98           174  human             18.5                 34.0  \n",
       "99           312  human             37.0                 84.5  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(datafile):\n",
    "    \"\"\"\n",
    "    Read your data into a single pandas dataframe where\n",
    "    - each row is an instance to be classified\n",
    "    (this could be a tweet, user, or news article, depending on your project)\n",
    "    - there is a column called `label` which stores the class label (e.g., the true\n",
    "      category for this row)\n",
    "    \"\"\"\n",
    "    bots = []\n",
    "    humans = []\n",
    "    folder = ['/bots', '/humans']\n",
    "    name = '/*.json.gz'\n",
    "    for f in folder:\n",
    "        paths = glob.glob(datafile + f + name)\n",
    "        for p in paths:\n",
    "            with gzip.open(p, 'r') as file:\n",
    "                for line in file:\n",
    "                    if f == folder[0]:\n",
    "                        bots.append(json.loads(line))\n",
    "                    elif f == folder[1]:\n",
    "                        humans.append(json.loads(line))\n",
    "    df_bots = pd.DataFrame(bots)[['screen_name','tweets','listed_count']]\n",
    "    df_bots['label'] = 'bot'\n",
    "    df_humans = pd.DataFrame(humans)[['screen_name','tweets','listed_count']]\n",
    "    df_humans['label'] = 'human'\n",
    "    frames = [df_bots, df_humans]\n",
    "    df = pd.concat(frames)\n",
    "    users = bots + humans\n",
    "    tweets = [u['tweets'] for u in users]\n",
    "    text = [d['full_text'] for t in tweets for d in t] \n",
    "\n",
    "#     tweets_avg_len = []\n",
    "    tweets_avg_mentions = []\n",
    "    tweets_avg_urls = []\n",
    "    factor = 100\n",
    "    for u in users:\n",
    "        tweets = u['tweets'] # a list of dicts\n",
    "        texts = [t['full_text'] for t in tweets]\n",
    "#         avg_len = sum(map(len, texts))/len(texts)\n",
    "#         tweets_avg_len.append(int(avg_len))\n",
    "        count_mention = 0\n",
    "        count_url = 0\n",
    "        for s in texts:\n",
    "            if 'http' in s:\n",
    "                count_url+=1\n",
    "            if '@' in s:\n",
    "                count_mention+=1\n",
    "        tweets_avg_urls.append(100 * count_url / len(texts))\n",
    "        tweets_avg_mentions.append(100 * count_mention / len(texts))\n",
    "#     df['tweets_avg_len'] = tweets_avg_len\n",
    "    df['tweets_avg_urls'] = tweets_avg_urls\n",
    "    df['tweets_avg_mentions'] = tweets_avg_mentions\n",
    "    return df\n",
    "# df = load_data('~/Dropbox/elevate/harassment/training_data/data.csv.gz')\n",
    "df = load_data('/Users/sheepman/Downloads/bots/small')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name             object\n",
       "tweets                  object\n",
       "listed_count             int64\n",
       "label                   object\n",
       "tweets_avg_urls        float64\n",
       "tweets_avg_mentions    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    labels_to_track = ['tweets_avg_urls', 'tweets_avg_mentions','listed_count']\n",
    "    for i, row in df.iterrows():\n",
    "        features = {}\n",
    "        features['tweets_avg_urls'] = row['tweets_avg_urls']\n",
    "        features['tweets_avg_mentions'] = row['tweets_avg_mentions']\n",
    "        features['listed_count'] = row['listed_count']\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "#     print(X)\n",
    "    return X, vec\n",
    "\n",
    "X, vec = make_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are dimensions of the feature matrix?\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweets_avg_urls': 2, 'tweets_avg_mentions': 1, 'listed_count': 0}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the feature names?\n",
    "# vocabulary_ is a dict from feature name to column index\n",
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweets_avg_urls\t9149\n",
      " tweets_avg_mentions\t7028\n",
      "        listed_count\t147695\n"
     ]
    }
   ],
   "source": [
    "# how often does each word occur?\n",
    "for word, idx in vec.vocabulary_.items():\n",
    "    print('%20s\\t%d' % (word, X[:,idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listed_count', 'tweets_avg_mentions', 'tweets_avg_urls']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also get a simple list of feature names:\n",
    "vec.get_feature_names()\n",
    "\n",
    "# e.g., first column is 'hate', second is 'love', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'bot': 100, 'human': 100})"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the row indices with hostile label\n",
    "np.where(y=='bot')[0]\n",
    "# np.where(y=='human')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweets_avg_urls\t                 bot\t3657\n",
      "     tweets_avg_urls\t               human\t5491\n",
      " tweets_avg_mentions\t                 bot\t905\n",
      " tweets_avg_mentions\t               human\t6123\n",
      "        listed_count\t                 bot\t2351\n",
      "        listed_count\t               human\t145344\n"
     ]
    }
   ],
   "source": [
    "# how often does each word appear in each class?\n",
    "for word, idx in vec.vocabulary_.items():\n",
    "    for class_name in class_names:\n",
    "        class_idx = np.where(y==class_name)[0]\n",
    "        print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, `you` appears more frequently in positive (hostile) class, and `love` appears more frequently in the negative (non-hostile) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a LogisticRegression classifier.\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01363247, 0.06014975, 0.0070873 ]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for binary classification, LogisticRegression stores a single coefficient vector\n",
    "clf.coef_\n",
    "# this would be a matrix for a multi-class probem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.01363247, -0.06014975, -0.0070873 ]), array([0.01363247, 0.06014975, 0.0070873 ])]\n"
     ]
    }
   ],
   "source": [
    "# for binary classification, the coefficients for the negative class is just the negative of the positive class.\n",
    "coef = [-clf.coef_[0], clf.coef_[0]]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for bot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listed_count</th>\n",
       "      <th>tweets_avg_mentions</th>\n",
       "      <th>tweets_avg_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013632</td>\n",
       "      <td>-0.06015</td>\n",
       "      <td>-0.007087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listed_count  tweets_avg_mentions  tweets_avg_urls\n",
       "0     -0.013632             -0.06015        -0.007087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for human\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listed_count</th>\n",
       "      <th>tweets_avg_mentions</th>\n",
       "      <th>tweets_avg_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.06015</td>\n",
       "      <td>0.007087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listed_count  tweets_avg_mentions  tweets_avg_urls\n",
       "0      0.013632              0.06015         0.007087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ci, class_name in enumerate(clf.classes_):\n",
    "    print('coefficients for %s' % class_name)\n",
    "    display(pd.DataFrame([coef[ci]], columns=vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top features for class   bot\n",
      "     tweets_avg_urls\t-0.0071\n",
      "        listed_count\t-0.0136\n",
      " tweets_avg_mentions\t-0.0601\n",
      "top features for class human\n",
      " tweets_avg_mentions\t0.0601\n",
      "        listed_count\t0.0136\n",
      "     tweets_avg_urls\t0.0071\n"
     ]
    }
   ],
   "source": [
    "# sort coefficients by class.\n",
    "features = vec.get_feature_names()\n",
    "for ci, class_name in enumerate(clf.classes_):\n",
    "    print('top features for class %5s' % class_name)\n",
    "    for fi in coef[ci].argsort()[::-1]: # descending order.\n",
    "        print('%20s\\t%.4f' % (features[fi], coef[ci][fi]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all cross-validation folds: [0.975, 0.875, 0.85, 1.0, 0.85]\n",
      "mean=0.91 std=0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train, test in kf.split(X):\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred = clf.predict(X[test])\n",
    "    accuracies.append(accuracy_score(y[test], pred))\n",
    "    \n",
    "    \n",
    "print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "print('mean=%.2f std=%.2f' % (np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
