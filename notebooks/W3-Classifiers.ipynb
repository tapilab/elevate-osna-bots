{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack # \"horizontal stack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweets</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>label</th>\n",
       "      <th>tweets_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carlos_eggbot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:07 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'You heard me! Shoot me.', 'Junpei, you...', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecolo_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:11 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"i'm not straight but 20 bucks is 20 bu\", '\"ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllStarSMBot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:28 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"You'll never know if you don't go\\nYou'll nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saionji_en</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:36:52 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"why the fuck am i banana girl? i'll never die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KimClune</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:37:20 +0000 201...</td>\n",
       "      <td>329</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Chewing rather than drinking breakfast is AWE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatsDogsBOT</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:38:10 +0000 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>'[Discussion] If I say no, that should be it. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bluejovanka</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:38:14 +0000 201...</td>\n",
       "      <td>47</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"I'm staying in tonight watching someone with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anittavota4</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:39:19 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT BrettHillOwens2: #PremiosMTVMIAW #MTVBRMUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>justtraveluk</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:39:21 +0000 201...</td>\n",
       "      <td>11</td>\n",
       "      <td>bot</td>\n",
       "      <td>'The Top 5 Airports in the World for Departure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rhaudiencebot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:40:08 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'GET BUTCH, BITCH!', 'HEY RIFF, WHAT DO YOU DO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LexyintheCity</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:40:11 +0000 201...</td>\n",
       "      <td>69</td>\n",
       "      <td>bot</td>\n",
       "      <td>'A happy belated to this crazy fucking gemini ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kimberlymaich</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:07 +0000 201...</td>\n",
       "      <td>11</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Donna Miller Fry Thank you for following me!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>timotheeribeiro</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:23 +0000 201...</td>\n",
       "      <td>65</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Pinned to mes voyages on @Pinterest: La renco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>666dikuto</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:42 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"I'll fight for us till death do us part\", \"I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GLaDOSystem</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:41:55 +0000 201...</td>\n",
       "      <td>21</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"But I overcame my handicap. That's a true sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gotpie_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:42:31 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Get in the pie joffrey', 'look the pie', 'L̲͚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pawtersimms1</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:44:14 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Tottenham vs Liverpool FREE live stream: Watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mikan02862611</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:11 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"Another hour! It's June 02, 2019 at 03:45AM\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WeatherTucson</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:12 +0000 201...</td>\n",
       "      <td>7</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Right now: Sunny and 92F. Today: Sunny. High ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>asta_ebooks</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:32 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>'When will there be a sequel to No.6 I need to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>taguigtwinktop</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:34 +0000 201...</td>\n",
       "      <td>10</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Hey Mackiedave@1988(@Mackiedave19881), thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stevenboss</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:45:44 +0000 201...</td>\n",
       "      <td>16</td>\n",
       "      <td>bot</td>\n",
       "      <td>'Today 2:00 and 7:00 pm. Support The Lord’s Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>latikia</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:46:14 +0000 201...</td>\n",
       "      <td>288</td>\n",
       "      <td>bot</td>\n",
       "      <td>'ICYMI: The Spelling Bee Champs Interview That...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>positivenagi</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:00 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>\"Take a break, you've done so much today I'm p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cheesucheesu</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:11 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'down for the clown!', 'nya ha ha!', 'my aesth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fetisbieber</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:50:43 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT Moomoocorner: BDBML #PremiosMTVMIAW #MTVLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>anittavota5</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:08 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT dj_rakete: #PremiosMTVMIAW #MTVBRMUSICALAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EngkoBoti</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:16 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>'get together : 함께 모이다.\\nAll the family get to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ZikaSdv</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:32 +0000 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>'RT monica1169: BDBML #PremiosMTVMIAW #MTVBRMU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lancxelot</td>\n",
       "      <td>[{'created_at': 'Sat Jun 01 18:51:27 +0000 201...</td>\n",
       "      <td>2</td>\n",
       "      <td>bot</td>\n",
       "      <td>'\"I\\'m very proud to be wearing this shirt eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RevolutApp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:32:51 +0000 201...</td>\n",
       "      <td>881</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@ghostraccoon87 We're sorry to hear that! 🙁 L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Bakari_Sellers</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:31:55 +0000 201...</td>\n",
       "      <td>1695</td>\n",
       "      <td>human</td>\n",
       "      <td>'@AsteadWesley It’s all good. I Just know ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:33:53 +0000 201...</td>\n",
       "      <td>943</td>\n",
       "      <td>human</td>\n",
       "      <td>'@parasjain777 In that case, please share your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:00 +0000 201...</td>\n",
       "      <td>289</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@juliabullia_ I am sorry you feel this way. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>fly2midway</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:23 +0000 201...</td>\n",
       "      <td>394</td>\n",
       "      <td>human</td>\n",
       "      <td>'Yesterday, Commissioner Jamie L. Rhee met wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>WaltThurm3</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:44 +0000 201...</td>\n",
       "      <td>573</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@AtlantaFalcons @KBDeuce4 @MattBosher5 @KBDeu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>scottjohnson</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:34:59 +0000 201...</td>\n",
       "      <td>2489</td>\n",
       "      <td>human</td>\n",
       "      <td>'Just a reminder that WE pay for tariffs. Have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TOIBengaluru</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:35:02 +0000 201...</td>\n",
       "      <td>400</td>\n",
       "      <td>human</td>\n",
       "      <td>'Animal assisted therapy finds more takers in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>LASchoolPolice</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:35:32 +0000 201...</td>\n",
       "      <td>173</td>\n",
       "      <td>human</td>\n",
       "      <td>'Shelter in place will be lifted at 12:10 PM d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bbmayabb</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:36:41 +0000 201...</td>\n",
       "      <td>34</td>\n",
       "      <td>human</td>\n",
       "      <td>'@caisersoze84 @SaadoonMustafa So elegant .. y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>livexlive</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:02 +0000 201...</td>\n",
       "      <td>67</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@halseyph Hey! Just letting you know that we’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Its_Katka</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:36:54 +0000 201...</td>\n",
       "      <td>281</td>\n",
       "      <td>human</td>\n",
       "      <td>'Like one guy said I was “on the way to the vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>OregonGovBrown</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:36 +0000 201...</td>\n",
       "      <td>913</td>\n",
       "      <td>human</td>\n",
       "      <td>\"Climate change threatens our communities, our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ExpressNews</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:40 +0000 201...</td>\n",
       "      <td>283</td>\n",
       "      <td>human</td>\n",
       "      <td>'Texas Legislature declines to expand Medicaid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ChuckWendig</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:49 +0000 201...</td>\n",
       "      <td>4138</td>\n",
       "      <td>human</td>\n",
       "      <td>'@veschwab Tell them the VE stands for VENGEAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>chrisdeville</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:37:50 +0000 201...</td>\n",
       "      <td>240</td>\n",
       "      <td>human</td>\n",
       "      <td>'A ban on all fiancée / Beyoncé rhymes', 'RT @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:14 +0000 201...</td>\n",
       "      <td>1566</td>\n",
       "      <td>human</td>\n",
       "      <td>'@aclaireporter @thetrainline Ah apologies abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>UNDPAzerbaijan</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:20 +0000 201...</td>\n",
       "      <td>80</td>\n",
       "      <td>human</td>\n",
       "      <td>'NOW HIRING: an experienced &amp;amp; motivated #E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>DrNerdLove</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:39 +0000 201...</td>\n",
       "      <td>228</td>\n",
       "      <td>human</td>\n",
       "      <td>'“Excuse me, do you have the time to talk abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>CharlesSoule</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:40 +0000 201...</td>\n",
       "      <td>617</td>\n",
       "      <td>human</td>\n",
       "      <td>'@tmalghem I’m sure there will be signed copie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>fordm</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:43 +0000 201...</td>\n",
       "      <td>1202</td>\n",
       "      <td>human</td>\n",
       "      <td>\"15 members of Britain's House of Lords have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ChadPawson</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:38:48 +0000 201...</td>\n",
       "      <td>84</td>\n",
       "      <td>human</td>\n",
       "      <td>\"Curious if there is anyone in B.C. who has no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ericvdunn</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:18 +0000 201...</td>\n",
       "      <td>646</td>\n",
       "      <td>human</td>\n",
       "      <td>'Hurricane season at midnight. Lord let these ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RossDellenger</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:25 +0000 201...</td>\n",
       "      <td>645</td>\n",
       "      <td>human</td>\n",
       "      <td>'In Mississippi, gaining \"resort status\" is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>MrGerryCampbell</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:36 +0000 201...</td>\n",
       "      <td>81</td>\n",
       "      <td>human</td>\n",
       "      <td>'Serving Police Officer arrested for a #Domest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>davidmweissman</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:39:59 +0000 201...</td>\n",
       "      <td>444</td>\n",
       "      <td>human</td>\n",
       "      <td>'@MiheerDodhia @sunny @ewarren @FoxNews I wrot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PaulRieckhoff</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:02 +0000 201...</td>\n",
       "      <td>1386</td>\n",
       "      <td>human</td>\n",
       "      <td>'Blah. Nobody wants this except Ortiz who gets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Monster</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:40 +0000 201...</td>\n",
       "      <td>3638</td>\n",
       "      <td>human</td>\n",
       "      <td>\"@ENIMSAJN_ A second job? If you're looking, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sligogaa</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:45 +0000 201...</td>\n",
       "      <td>174</td>\n",
       "      <td>human</td>\n",
       "      <td>'U17 Connacht League Rd2\\n\\n10mins 1st half\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FunSizeSuze</td>\n",
       "      <td>[{'created_at': 'Fri May 31 18:40:46 +0000 201...</td>\n",
       "      <td>312</td>\n",
       "      <td>human</td>\n",
       "      <td>'@soozaphone @cosmicshambles Ooh, yes! *pulls ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                             tweets  \\\n",
       "0    carlos_eggbot  [{'created_at': 'Sat Jun 01 18:36:07 +0000 201...   \n",
       "1     ecolo_ebooks  [{'created_at': 'Sat Jun 01 18:36:11 +0000 201...   \n",
       "2     AllStarSMBot  [{'created_at': 'Sat Jun 01 18:36:28 +0000 201...   \n",
       "3       saionji_en  [{'created_at': 'Sat Jun 01 18:36:52 +0000 201...   \n",
       "4         KimClune  [{'created_at': 'Sat Jun 01 18:37:20 +0000 201...   \n",
       "..             ...                                                ...   \n",
       "95  davidmweissman  [{'created_at': 'Fri May 31 18:39:59 +0000 201...   \n",
       "96   PaulRieckhoff  [{'created_at': 'Fri May 31 18:40:02 +0000 201...   \n",
       "97         Monster  [{'created_at': 'Fri May 31 18:40:40 +0000 201...   \n",
       "98        sligogaa  [{'created_at': 'Fri May 31 18:40:45 +0000 201...   \n",
       "99     FunSizeSuze  [{'created_at': 'Fri May 31 18:40:46 +0000 201...   \n",
       "\n",
       "    listed_count  label                                       tweets_texts  \n",
       "0              0    bot  'You heard me! Shoot me.', 'Junpei, you...', '...  \n",
       "1              2    bot  \"i'm not straight but 20 bucks is 20 bu\", '\"ec...  \n",
       "2              3    bot  \"You'll never know if you don't go\\nYou'll nev...  \n",
       "3              3    bot  \"why the fuck am i banana girl? i'll never die...  \n",
       "4            329    bot  'Chewing rather than drinking breakfast is AWE...  \n",
       "..           ...    ...                                                ...  \n",
       "95           444  human  '@MiheerDodhia @sunny @ewarren @FoxNews I wrot...  \n",
       "96          1386  human  'Blah. Nobody wants this except Ortiz who gets...  \n",
       "97          3638  human  \"@ENIMSAJN_ A second job? If you're looking, w...  \n",
       "98           174  human  'U17 Connacht League Rd2\\n\\n10mins 1st half\\nS...  \n",
       "99           312  human  '@soozaphone @cosmicshambles Ooh, yes! *pulls ...  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(directory):\n",
    "    bots = []\n",
    "    humans = []\n",
    "    folder = ['/bots', '/humans']\n",
    "    name = '/*.json.gz'\n",
    "    for f in folder:\n",
    "        paths = glob.glob(directory + f + name)\n",
    "        for p in paths:\n",
    "            with gzip.open(p, 'r') as file:\n",
    "                for line in file:\n",
    "                    if f == folder[0]:\n",
    "                        js = json.loads(line)\n",
    "                        if 'tweets' in js:\n",
    "                            bots.append(js)\n",
    "                    elif f == folder[1]:\n",
    "                        js = json.loads(line)\n",
    "                        if 'tweets' in js:\n",
    "                            humans.append(js)\n",
    "    df_bots = pd.DataFrame(bots)[['screen_name', 'tweets', 'listed_count']]\n",
    "    df_bots['label'] = 'bot'\n",
    "    df_humans = pd.DataFrame(humans)[['screen_name', 'tweets', 'listed_count']]\n",
    "    df_humans['label'] = 'human'\n",
    "    frames = [df_bots, df_humans]\n",
    "    df = pd.concat(frames)\n",
    "    users = bots + humans\n",
    "    # tweets_avg_mentions = []\n",
    "    # tweets_avg_urls = []\n",
    "    # factor = 100\n",
    "    tweets_texts = []\n",
    "    for u in users:\n",
    "        tweets = u['tweets']  # a list of dicts\n",
    "        texts = [t['full_text'] for t in tweets]\n",
    "        tweets_texts.append(str(texts).strip('[]'))\n",
    "    df['tweets_texts'] = tweets_texts\n",
    "    return df\n",
    "df = load_data('/Users/sheepman/Downloads/bots/small')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name     object\n",
       "tweets          object\n",
       "listed_count     int64\n",
       "label           object\n",
       "tweets_texts    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_features(texts):\n",
    "    count_mention = 0\n",
    "    count_url = 0\n",
    "    factor = 100\n",
    "    features = {}\n",
    "    for s in texts:\n",
    "        if 'http' in s:\n",
    "            count_url += 1\n",
    "        if '@' in s:\n",
    "            count_mention += 1\n",
    "    if len(texts) == 0:\n",
    "        features['tweets_avg_urls'] = 0\n",
    "        features['tweets_avg_mentions'] = 0\n",
    "    else:\n",
    "        features['tweets_avg_urls'] = factor * count_url / len(texts)\n",
    "        features['tweets_avg_mentions'] = factor * count_mention / len(texts)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    ## Add your code to create features.\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    for i, row in df.iterrows():\n",
    "        tweets = row['tweets']\n",
    "        texts = [t['full_text'] for t in tweets]\n",
    "        features = get_tweets_features(texts)\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweets_avg_urls': 1, 'tweets_avg_mentions': 0}\n"
     ]
    }
   ],
   "source": [
    "X, dict_vec = make_features(df)\n",
    "print(dict_vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(min_df=0.03, max_df=0.8, ngram_range=(3, 3))\n",
    "X_words = count_vec.fit_transform(df.tweets_texts)\n",
    "# get_f(count_vec, X_words)\n",
    "optimal_X_all = hstack([X, X_words]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtvbrclipebanana mtvbrhinobolarebola mtvbrfeatondadiferente\t1400\n",
      "mtvbrmusicalanitta mtvbrclipebanana mtvbrhinobolarebola\t1400\n",
      "mtvlastoriesanitta mtvlaviralanitta mtvlashiprip\t1200\n",
      "          01 2019 at\t661\n",
      "        june 01 2019\t661\n",
      "       thank you for\t482\n",
      "       here https co\t277\n",
      "       more https co\t275\n",
      "         at https co\t270\n",
      "         to https co\t256\n"
     ]
    }
   ],
   "source": [
    "# top terms?\n",
    "def print_top_words(X_words, count_vec, n=10):\n",
    "    features = count_vec.get_feature_names()\n",
    "    word_counts = X_words.sum(axis=0).A1\n",
    "    for i in np.argsort(word_counts)[::-1][:n]:\n",
    "        print('%20s\\t%d' % (features[i], word_counts[i]))\n",
    "\n",
    "print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1041)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)\n",
    "optimal_X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweets_avg_urls\t               human\t5491\n",
      "     tweets_avg_urls\t                 bot\t3657\n",
      " tweets_avg_mentions\t               human\t6123\n",
      " tweets_avg_mentions\t                 bot\t905\n"
     ]
    }
   ],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)\n",
    "# how often does each word appear in each class?\n",
    "for word, idx in dict_vec.vocabulary_.items():\n",
    "    for class_name in class_names:\n",
    "        class_idx = np.where(y==class_name)[0]\n",
    "        print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_sizes=10, alpha=0.001000\n",
      "mean=0.82 std=0.07\n",
      "\n",
      "hidden_layer_sizes=10, alpha=0.000100\n",
      "mean=0.81 std=0.03\n",
      "\n",
      "hidden_layer_sizes=10, alpha=0.000010\n",
      "mean=0.81 std=0.05\n",
      "\n",
      "hidden_layer_sizes=50, alpha=0.001000\n",
      "mean=0.84 std=0.05\n",
      "\n",
      "hidden_layer_sizes=50, alpha=0.000100\n",
      "mean=0.80 std=0.05\n",
      "\n",
      "hidden_layer_sizes=50, alpha=0.000010\n",
      "mean=0.83 std=0.06\n",
      "\n",
      "hidden_layer_sizes=100, alpha=0.001000\n",
      "mean=0.84 std=0.05\n",
      "\n",
      "hidden_layer_sizes=100, alpha=0.000100\n",
      "mean=0.86 std=0.05\n",
      "\n",
      "hidden_layer_sizes=100, alpha=0.000010\n",
      "mean=0.84 std=0.05\n",
      "\n",
      "hidden_layer_sizes=200, alpha=0.001000\n",
      "mean=0.88 std=0.06\n",
      "\n",
      "hidden_layer_sizes=200, alpha=0.000100\n",
      "mean=0.85 std=0.07\n",
      "\n",
      "hidden_layer_sizes=200, alpha=0.000010\n",
      "mean=0.84 std=0.05\n",
      "\n",
      "hidden_layer_size=10\n",
      "alpha\t\taccuracy\n",
      "0.001000\t0.820000\n",
      "0.000100\t0.810000\n",
      "0.000010\t0.800000\n",
      "\n",
      "hidden_layer_size=50\n",
      "alpha\t\taccuracy\n",
      "0.001000\t0.840000\n",
      "0.000100\t0.800000\n",
      "0.000010\t0.830000\n",
      "\n",
      "hidden_layer_size=100\n",
      "alpha\t\taccuracy\n",
      "0.001000\t0.840000\n",
      "0.000100\t0.860000\n",
      "0.000010\t0.840000\n",
      "\n",
      "hidden_layer_size=200\n",
      "alpha\t\taccuracy\n",
      "0.001000\t0.880000\n",
      "0.000100\t0.850000\n",
      "0.000010\t0.840000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a= [10,50,100,200]\n",
    "b = [ 0.001, 0.0001, 0.00001]\n",
    "mean_accuracies = np.zeros((4, 3), dtype=np.float)\n",
    "for row_idx, hidden_layer_sizes in enumerate(a):\n",
    "    for col_idx, alpha in enumerate(b):\n",
    "        print(\"hidden_layer_sizes=%d, alpha=%f\"%(hidden_layer_sizes,alpha))\n",
    "        clf = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes , activation='relu', solver='adam', alpha=alpha, max_iter=500)\n",
    "        clf.fit(optimal_X_all, y)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        accuracies = []\n",
    "        for train, test in kf.split(optimal_X_all):\n",
    "            clf.fit(optimal_X_all[train], y[train])\n",
    "            pred = clf.predict(optimal_X_all[test])\n",
    "            accuracies.append(accuracy_score(y[test], pred))\n",
    "            clf.coefs_\n",
    "        mean_accuracies[row_idx][col_idx] = str(round(np.mean(accuracies), 2))\n",
    "#         print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "        print('mean=%.2f std=%.2f\\n' % (np.mean(accuracies), np.std(accuracies)))\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"hidden_layer_size=%d\\nalpha\\t\\taccuracy\"%a[i])\n",
    "    row_str = []\n",
    "    for j in range(3):\n",
    "        print('%f\\t%f'%(b[j],mean_accuracies[i][j]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf=1, n_estimators=100\n",
      "mean=0.88 std=0.04\n",
      "\n",
      "min_samples_leaf=1, n_estimators=200\n",
      "mean=0.88 std=0.05\n",
      "\n",
      "min_samples_leaf=1, n_estimators=300\n",
      "mean=0.89 std=0.05\n",
      "\n",
      "min_samples_leaf=3, n_estimators=100\n",
      "mean=0.88 std=0.03\n",
      "\n",
      "min_samples_leaf=3, n_estimators=200\n",
      "mean=0.89 std=0.04\n",
      "\n",
      "min_samples_leaf=3, n_estimators=300\n",
      "mean=0.88 std=0.02\n",
      "\n",
      "min_samples_leaf=5, n_estimators=100\n",
      "mean=0.87 std=0.03\n",
      "\n",
      "min_samples_leaf=5, n_estimators=200\n",
      "mean=0.88 std=0.03\n",
      "\n",
      "min_samples_leaf=5, n_estimators=300\n",
      "mean=0.88 std=0.05\n",
      "\n",
      "min_samples_leaf=1\n",
      "n_estimators\taccuracy\n",
      "100.000000\t0.880000\n",
      "200.000000\t0.880000\n",
      "300.000000\t0.890000\n",
      "\n",
      "min_samples_leaf=3\n",
      "n_estimators\taccuracy\n",
      "100.000000\t0.880000\n",
      "200.000000\t0.880000\n",
      "300.000000\t0.880000\n",
      "\n",
      "min_samples_leaf=5\n",
      "n_estimators\taccuracy\n",
      "100.000000\t0.870000\n",
      "200.000000\t0.880000\n",
      "300.000000\t0.880000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "c= [1, 3, 5]\n",
    "d = [100, 200, 300]\n",
    "mean_accuracies = np.zeros((3, 3), dtype=np.float)\n",
    "for row_idx, min_samples_leaf in enumerate(c):\n",
    "    for col_idx, n_estimators in enumerate(d):\n",
    "        print(\"min_samples_leaf=%d, n_estimators=%d\"%(min_samples_leaf,n_estimators))\n",
    "        rand = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf= min_samples_leaf)\n",
    "        rand.fit(optimal_X_all, y)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        accuracies = []\n",
    "        for train, test in kf.split(optimal_X_all):\n",
    "            rand.fit(optimal_X_all[train], y[train])\n",
    "            pred = rand.predict(optimal_X_all[test])\n",
    "            accuracies.append(accuracy_score(y[test], pred))\n",
    "#         print(rand.feature_importances_)\n",
    "        mean_accuracies[row_idx][col_idx] = str(round(np.mean(accuracies), 2))\n",
    "#         print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "        print('mean=%.2f std=%.2f\\n' % (np.mean(accuracies), np.std(accuracies)))\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"min_samples_leaf=%d\\nn_estimators\\taccuracy\"%c[i])\n",
    "    row_str = []\n",
    "    for j in range(3):\n",
    "        print('%f\\t%f'%(d[j],mean_accuracies[i][j]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
